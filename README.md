# llama_server
Local FastAPI server using Llama to generate responses, accessible locally or through REST API calls
